{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fauci-email-graph.json\") as f:\n",
    "    data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 nodes in SCC\n"
     ]
    }
   ],
   "source": [
    "emails = data[\"emails\"]\n",
    "names = data[\"names\"]\n",
    "clusters = data[\"clusters\"]\n",
    "\n",
    "keep = set(range(len(names) + 1))\n",
    "while True:\n",
    "    inds = []\n",
    "    all_s = []\n",
    "    all_r = []\n",
    "    all_c = []\n",
    "\n",
    "    for chain in emails:\n",
    "        for email in chain:\n",
    "            s = email[\"sender\"]            \n",
    "            if s not in keep: continue\n",
    "            \n",
    "            recipients = [r for r in email[\"recipients\"] if r in keep]\n",
    "            ccs = [c for c in email[\"cc\"] if c in keep]\n",
    "            \n",
    "            num_inds = len(recipients) * len(ccs)\n",
    "            if num_inds == 0: continue\n",
    "        \n",
    "            all_s.append(s)\n",
    "            for r in recipients: all_r.append(r)\n",
    "            for c in ccs: all_c.append(c)\n",
    "        \n",
    "            for r in recipients:\n",
    "                for c in ccs:\n",
    "                    inds.append((s, r, c, 1.0 / num_inds))\n",
    "                    \n",
    "    new_keep = set(all_s).intersection(set(all_r)).intersection(set(all_c))\n",
    "    no_updates = (new_keep == keep)\n",
    "    keep = new_keep\n",
    "    if no_updates or len(new_keep) == 0:\n",
    "        break\n",
    "    else:\n",
    "        keep = new_keep\n",
    "\n",
    "keep = sorted(list(keep))        \n",
    "dim = len(keep)\n",
    "print(dim, \"nodes in SCC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1413 emails\n"
     ]
    }
   ],
   "source": [
    "clean_names = [names[k] for k in keep]\n",
    "clean_clusters = [clusters[k] for k in keep]\n",
    "id_map = {k : i for (i, k) in enumerate(keep)}\n",
    "clean_inds = [(id_map[s], id_map[r], id_map[c], v) for (s, r, c, v) in inds]\n",
    "print(len(clean_inds), \"emails\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "551 unique cc/receiver/sender indices\n"
     ]
    }
   ],
   "source": [
    "# Merge indices having multiple values\n",
    "combined_inds = {}\n",
    "for (s, r, c, v) in clean_inds:\n",
    "    index = (c, r, s)\n",
    "    if index not in combined_inds:\n",
    "        combined_inds[index] = 0.0\n",
    "    combined_inds[index] += v\n",
    "\n",
    "num_entries = len(combined_inds)    \n",
    "print(num_entries, \"unique cc/receiver/sender indices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out human-readable json\n",
    "tensor_fname = 'cc-recipient-sender-tensor.json'\n",
    "with open(tensor_fname, \"w\") as f:\n",
    "    f.write('{\\n')\n",
    "    \n",
    "    # tensor dimensions / number of nodes ^ 3\n",
    "    f.write('\"dimensions\": [\\n') \n",
    "    f.write(f'[{dim}, {dim}, {dim}]\\n')\n",
    "    f.write('],\\n')\n",
    "    \n",
    "    # number of entries\n",
    "    f.write('\"num_entries\": [\\n')\n",
    "    f.write(f'{num_entries}\\n')\n",
    "    f.write('],\\n')\n",
    "    \n",
    "    # tensor entries (index and value)\n",
    "    f.write('\"entries\": [\\n')\n",
    "    for (i, index) in enumerate(combined_inds):\n",
    "        extra = ',' if i < len(combined_inds) - 1 else ''\n",
    "        c, r, s = index\n",
    "        v = combined_inds[index]        \n",
    "        f.write(f'[{c}, {r}, {s}, {v}]{extra}\\n')\n",
    "    f.write('],\\n')\n",
    "    \n",
    "    # names of people\n",
    "    f.write('\"names\": [\\n')    \n",
    "    for (i, name) in enumerate(clean_names):\n",
    "        extra = ',' if i < len(clean_names) - 1 else ''        \n",
    "        f.write(f'\"{name}\"{extra}\\n')\n",
    "    f.write('],\\n')\n",
    "    \n",
    "    # clusters / organizations of people\n",
    "    f.write('\"clusters\": [\\n')    \n",
    "    for (i, cluster) in enumerate(clean_clusters):\n",
    "        extra = ',' if i < len(clean_clusters) - 1 else ''        \n",
    "        f.write(f'{cluster}{extra}\\n')\n",
    "    f.write(']\\n')\n",
    "    \n",
    "    f.write('}\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that we can load the json\n",
    "with open(tensor_fname) as f:\n",
    "    tensor = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
